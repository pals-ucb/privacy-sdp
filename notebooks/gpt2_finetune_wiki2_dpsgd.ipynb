{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5619ec11-0df7-441d-891d-611933419b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cff62d-8c3d-4c61-b6a4-e9e1a2112e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BAXKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77b777c-4f91-4c2f-8316-be66f045e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "#import keras_nlp\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasAdamOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ad7475-27fd-4f0c-bab4-f47db4d0afe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.14.0\n"
     ]
    }
   ],
   "source": [
    "#keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41ed6138-babc-4b52-9bf4-08713c01053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/pals/MICS/MICS_207/Project'\n",
    "wikitext2_root = root + '/datasets/kaggle-wikitext/wikitext-2/'\n",
    "train_file = wikitext2_root + 'wiki.train.tokens'\n",
    "test_file  = wikitext2_root + 'wiki.test.tokens'\n",
    "valid_file = wikitext2_root + 'wiki.valid.tokens'\n",
    "unittest_file = wikitext2_root + 'unittest.tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be54b6fb-4bdc-497c-9f1c-3f498311b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 3\n",
    "SEQUENCE_LENGTH = 128\n",
    "#BLOCK_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af90fb2-dd5d-4d5d-95cb-75972cc8c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, max_length=SEQUENCE_LENGTH):\n",
    "    data = None\n",
    "    with open(file_path, 'r', encoding='utf-8') as fd:\n",
    "        data = fd.read()\n",
    "    tokens = tokenizer(data, return_tensors='tf', padding='max_length', truncation=True, max_length=max_length)\n",
    "    return tf.data.Dataset.from_tensor_slices((tokens['input_ids'], tokens['attention_mask']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ca0c10ca-d99d-4c30-b0ac-4ee634d91c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "#gpt2_tokenizer.padding_side = 'left'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "61cb68bc-8b88-4a2c-bedf-b341fad06257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_file, gpt2_tokenizer).shuffle(buffer_size=1024).batch(BATCH_SIZE)\n",
    "test_dataset  = load_dataset(test_file, gpt2_tokenizer).batch(BATCH_SIZE)\n",
    "valid_dataset = load_dataset(valid_file, gpt2_tokenizer).batch(BATCH_SIZE)\n",
    "unittest_dataset = load_dataset(unittest_file, gpt2_tokenizer).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5cbc4d28-015b-4c59-8789-f9d4a82914f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.layers.core.embedding.Embedding at 0x32edca200>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "gpt2_lm = TFGPT2LMHeadModel.from_pretrained(model_name)\n",
    "gpt2_lm.resize_token_embeddings(len(gpt2_tokenizer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e5989d4-3234-461d-b944-fdcb302c8385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLay  multiple                  124439808 \n",
      " er)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124439808 (474.70 MB)\n",
      "Trainable params: 124439808 (474.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3d8f4e8-00cb-4491-b27b-2681a4b1c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = DPKerasAdamOptimizer(\n",
    "    l2_norm_clip=1.0,\n",
    "    noise_multiplier=1.1,\n",
    "    num_microbatches=8,\n",
    "    learning_rate=1e-4\n",
    ")\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4342ce3-8cbe-4142-9706-efb5393df215",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f5133-1cf1-41c0-9409-fe1e8eab60f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b85a243b-a940-4ba5-84a3-566aca4c44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_text, max_length=256):\n",
    "    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='tf')\n",
    "    attention_mask = tf.ones_like(input_ids)\n",
    "    outputs   = gpt2_lm.generate(input_ids, max_length = max_length, attention_mask=attention_mask, \n",
    "                                 num_return_sequences=5,\n",
    "                                 no_repeat_ngram_size=2,  # Avoid repeating n-grams of size 2\n",
    "                                 top_k=25,  # Limits the sampling pool to top_k tokens\n",
    "                                 do_sample=True,\n",
    "                                 temperature = 10.0,\n",
    "                                 #top_p=0.95, \n",
    "                                 pad_token_id=gpt2_tokenizer.eos_token_id)\n",
    "    gen_text  = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef64efe4-7ceb-4dd0-9312-b5d4774fc123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went on a trip to see Tajmahal in Agra. My trip was really interesting, a big show from both a fan of The Rock's sound-craftsmanship. You'll meet more fans for this show through a couple nights than most of his live productions will see during shows.\n",
      "\n",
      "The tour also had some nice performances on stage which gave some laughs throughout:\n",
      "\n",
      " of Jaxxon (the latter one is very special as we all can guess).\n",
      "- A few highlights were this live: -The only surprise (no word how big) in here in Mumbai! : - A nice live performance here at BMO\n",
      "—This post on social Media\n",
      " I have seen more than once. But we had no other idea there might even are live live show shows on here\n",
      " I didn, because if no one really cares that you'll die, don, this tour and it has some special, amazing live experiences you know will last a month of yours! — A live gig. -\n",
      "We had several other experiences like watching The Big Boss Band show at an Odez on Friday where some shows ended up here and others had them going straight onto a bus! - In any tour we like to make, and this trip did one good thing\n"
     ]
    }
   ],
   "source": [
    "print(generate('I went on a trip to see Tajmahal in Agra. My trip was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6eb0ae0d-433f-4932-9adb-9f582d06ed22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training step\n",
    "@tf.function\n",
    "def train_step(input_ids, attention_mask):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Shift the input IDs and get the labels\n",
    "        labels = tf.concat([input_ids[:, 1:], tf.fill([input_ids.shape[0], 1], tokenizer.pad_token_id)], axis=-1)\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "        loss = loss_fn(labels, logits)\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af70f53f-5bb3-422b-9b97-8280647f314e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f80777-21b3-4a6c-b94c-1d83e6e326d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d9a801-f6bf-4234-aae6-404cde95ce9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abffe5d3-ee50-4d3f-8fbe-bfaf57a067e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 128), dtype=tf.int32, name=None), TensorSpec(shape=(None, 128), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "333cc108-7947-490b-b825-a112ea1fd8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
      "array([[  220,   198,   796,   569, 18354,  7496, 17740,  6711,   796,\n",
      "          220,   198,   220,   198,  2311,    73, 13090,   645,   569,\n",
      "        18354,  7496,   513,  1058,  1279,  2954,    29, 17740,   357,\n",
      "         4960,  1058, 10545,   230,    99,   161,   254,   112,  5641,\n",
      "        44444,  9202, 25084, 24440, 12675, 11839,    18,   837,  6578,\n",
      "          764,   569, 18354,  7496,   286,   262, 30193,   513,  1267,\n",
      "          837,  8811,  6412,   284,   355,   569, 18354,  7496, 17740,\n",
      "         6711,  2354,  2869,   837,   318,   257, 16106,  2597,  2488,\n",
      "           12,    31,  2712,  2008,   983,  4166,   416, 29490,   290,\n",
      "         6343,    13, 44206,   329,   262, 14047, 44685,   764, 28728,\n",
      "          287,  3269,  2813,   287,  2869,   837,   340,   318,   262,\n",
      "         2368,   983,   287,   262,   569, 18354,  7496,  2168,   764,\n",
      "         1279,  2954,    29,   262,   976, 21748,   286, 16106,   290,\n",
      "         1103,  2488,    12,    31,   640, 11327,   355,   663, 27677,\n",
      "          837,   262]], dtype=int32)>, <tf.Tensor: shape=(1, 128), dtype=int32, numpy=\n",
      "array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
      "      dtype=int32)>)\n"
     ]
    }
   ],
   "source": [
    "for x in train_dataset:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42481f8-bf0f-4a86-a4a4-08c2599da206",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489d67f5-390e-460a-b1e4-9179a76dd34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "# Training loop\n",
    "for epoch in range(3):\n",
    "    print(f'Epoch {epoch + 1}')\n",
    "    for step, (input_ids, attention_mask) in enumerate(train_dataset):\n",
    "        loss = train_step(input_ids, attention_mask)\n",
    "        if step % 100 == 0:\n",
    "            print(f'Step {step}, Loss: {loss.numpy()}')\n",
    "\n",
    "en = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0ff8f-76af-4294-8541-fb81a2f9aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = gpt2_lm.evaluate(test_dataset)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47232be6-4062-4e07-9d3a-15a289012fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'Training time {(en-st)/3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c39afa-de0d-4982-ba6c-4a12237218b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generate('I went on a trip to see Tajmahal in Agra. My trip was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd54f7d-6ff4-4667-943e-7f3826605375",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
