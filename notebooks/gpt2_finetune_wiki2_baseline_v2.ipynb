{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5619ec11-0df7-441d-891d-611933419b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63cff62d-8c3d-4c61-b6a4-e9e1a2112e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BAXKEND']='tensorflow'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f77b777c-4f91-4c2f-8316-be66f045e0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "#import keras_nlp\n",
    "import tensorflow as tf\n",
    "from transformers import TFGPT2LMHeadModel, GPT2Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8ad7475-27fd-4f0c-bab4-f47db4d0afe7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.16.2\n"
     ]
    }
   ],
   "source": [
    "#keras.mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "print(tf.__version__)\n",
    "#tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41ed6138-babc-4b52-9bf4-08713c01053f",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/pals/MICS/MICS_207/Project/datasets'\n",
    "wikitext2_root = root + '/kaggle-wikitext/wikitext-2/'\n",
    "train_file = wikitext2_root + 'wiki.train.tokens'\n",
    "test_file  = wikitext2_root + 'wiki.test.tokens'\n",
    "valid_file = wikitext2_root + 'wiki.valid.tokens'\n",
    "unittest_file = wikitext2_root + 'unittest.tokens'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be54b6fb-4bdc-497c-9f1c-3f498311b7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8\n",
    "NUM_EPOCHS = 1\n",
    "SEQUENCE_LENGTH = 512\n",
    "SHUFFLE_SIZE = 128\n",
    "#BLOCK_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed0555e-7b74-44b6-afae-6217916e3921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode input text using the tokenizer provided\n",
    "def encode(text, tokenizer, max_length=SEQUENCE_LENGTH):\n",
    "    tokens = tokenizer.encode(text, padding='max_length', truncation=True, max_length=max_length)\n",
    "    input_ids = tf.constant(tokens, dtype=tf.int32)\n",
    "    attention_mask = tf.constant([1 if token != tokenizer.pad_token_id else 0 for token in tokens], dtype=tf.int32)\n",
    "    return input_ids, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af90fb2-dd5d-4d5d-95cb-75972cc8c822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(file_path, tokenizer, max_length=SEQUENCE_LENGTH):\n",
    "    lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as fd:\n",
    "        for line in fd:\n",
    "            sline = line.strip()\n",
    "            if len(sline) > 0:\n",
    "                lines.append(sline)\n",
    "    input_ids, attention_masks = zip(*[encode(line, tokenizer, max_length=max_length) for line in lines])\n",
    "    input_ids = tf.stack(input_ids)\n",
    "    attention_masks = tf.stack(attention_masks)\n",
    "    return tf.data.Dataset.from_tensor_slices((input_ids, attention_masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca0c10ca-d99d-4c30-b0ac-4ee634d91c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "#gpt2_tokenizer.padding_side = 'left'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61cb68bc-8b88-4a2c-bedf-b341fad06257",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = load_dataset(train_file, gpt2_tokenizer).shuffle(buffer_size=SHUFFLE_SIZE).batch(BATCH_SIZE)\n",
    "test_dataset  = load_dataset(test_file, gpt2_tokenizer).batch(BATCH_SIZE)\n",
    "valid_dataset = load_dataset(valid_file, gpt2_tokenizer).batch(BATCH_SIZE)\n",
    "unittest_dataset = load_dataset(unittest_file, gpt2_tokenizer).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e9aa91-b339-492e-814e-81800fdf15de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
      "array([[15496,  2159,    13, ..., 50256, 50256, 50256],\n",
      "       [49488,   318,  2901, ..., 50256, 50256, 50256],\n",
      "       [34784,  1365,  1110, ..., 50256, 50256, 50256]], dtype=int32)>, <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
      "array([[1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0],\n",
      "       [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-04 09:23:14.018793: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for ele in unittest_dataset:\n",
    "    print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "422a24cb-838e-419f-865c-150d0d4b5491",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 512), dtype=tf.int32, name=None), TensorSpec(shape=(None, 512), dtype=tf.int32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(unittest_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cbc4d28-015b-4c59-8789-f9d4a82914f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFGPT2LMHeadModel.\n",
      "\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf_keras.src.layers.core.embedding.Embedding at 0x32dc00a00>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = 'gpt2'\n",
    "#model_name = \"./gpt2_saved_v1\"\n",
    "gpt2_lm = TFGPT2LMHeadModel.from_pretrained(model_name)\n",
    "gpt2_lm.resize_token_embeddings(len(gpt2_tokenizer)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3e5989d4-3234-461d-b944-fdcb302c8385",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLay  multiple                  124439808 \n",
      " er)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124439808 (474.70 MB)\n",
      "Trainable params: 124439808 (474.70 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3d8f4e8-00cb-4491-b27b-2681a4b1c297",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "optimizer = DPKerasAdamOptimizer(\n",
    "    l2_norm_clip=1.0,\n",
    "    noise_multiplier=1.1,\n",
    "    num_microbatches=8,\n",
    "    learning_rate=1e-4\n",
    ")\n",
    "'''\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=1e-4)\n",
    "'''\n",
    "optimizer + tf.keras.optimizers.SGD(learning_rate = 0.01,\n",
    "                                momentum=0.0, \n",
    "                                nesterov=False, \n",
    "                                name='SGD')\n",
    "'''                                \n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4342ce3-8cbe-4142-9706-efb5393df215",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b85a243b-a940-4ba5-84a3-566aca4c44bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_text, max_length=256):\n",
    "    input_ids = gpt2_tokenizer.encode(input_text, return_tensors='tf')\n",
    "    attention_mask = tf.ones_like(input_ids)\n",
    "    outputs   = gpt2_lm.generate(input_ids, max_length = max_length, attention_mask=attention_mask, \n",
    "                                 num_return_sequences=5,\n",
    "                                 no_repeat_ngram_size=2,  # Avoid repeating n-grams of size 2\n",
    "                                 top_k=25,  # Limits the sampling pool to top_k tokens\n",
    "                                 do_sample=True,\n",
    "                                 temperature = 10.0,\n",
    "                                 #top_p=0.95, \n",
    "                                 pad_token_id=gpt2_tokenizer.eos_token_id)\n",
    "    gen_text  = gpt2_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ef64efe4-7ceb-4dd0-9312-b5d4774fc123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went on a trip to see Tajmahal in Agra. My trip was quite different but the journey made me remember one aspect when they visited here in Mumbai – I couldn'sn´l meet Taj Mahahm – which I have forgotten the very thing I went so many weeks. So we went from Saraj to Nagari from then onward to go to Jain as Taj has no such highways from that era\". (Chermish) He is trying a much smaller pilgrimage this past summer than the first half-year. However one person was not surprised about being told he does now live there too. The last Taj is now going out into Bijaji to do his last solo performance from this stage on May 15 here and at least his audience may enjoy watching some other artists get to experience something special through their instruments and melodies (as there does exist for us a band named Srinivas) as a last few guests come through our back hall during his next concert in May 2014 as we had not come close after just this time for several minutes when Taj mutes it out with two others like the song Aptissai's Sisne & Bismuttis's Arpula with Taro & Nell for our very good concert,\n"
     ]
    }
   ],
   "source": [
    "print(generate('I went on a trip to see Tajmahal in Agra. My trip was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "489d67f5-390e-460a-b1e4-9179a76dd34a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function infer_framework at 0x32579d090> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function infer_framework at 0x32579d090> and will run it as-is.\n",
      "Cause: for/else statement not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "2971/2971 [==============================] - 22739s 8s/step - loss: 0.0072 - accuracy: 0.9991 - val_loss: 4.4741e-07 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "history = gpt2_lm.fit(\n",
    "    train_dataset,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    validation_data=valid_dataset\n",
    ")\n",
    "en = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0ff8f-76af-4294-8541-fb81a2f9aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, accuracy = gpt2_lm.evaluate(test_dataset)\n",
    "print(f'Test Loss: {loss}')\n",
    "print(f'Test Accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47232be6-4062-4e07-9d3a-15a289012fa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time 6.316470919516352 hours\n"
     ]
    }
   ],
   "source": [
    "print(f'Training time {(en-st)/3600} hours')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90c39afa-de0d-4982-ba6c-4a12237218b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I went on a trip to see Tajmahal in Agra. My trip was\" \"H\",A\".!\"\"B(s\"M\"-D\"\"I.\"I,\"L\"!\"I wasAA[\"[\"\"!\"\",\"S\",\"\"I\"...\"\"\"!L:\"\".I\"!AH.\"\"s\"[\"\"\".\",S#1\"H\"'DHe\"-\"\"!!\"L(I>\"\"A\"P\"?D...\"\"\"...\"(\",I\")He\"He\"...The\",\"[!\"\"(S(!\"!\"A,\"\"-)\"-\"?\"\"\".In(\"...D(...\">\"#H)\"?\",\"I()\"\"!He\"….\"The\"!\":\",\"-!\"\n",
      "IThe\"(AThe\"...\"\"- \"!\"\"...!!\"He\".\".\"\".\"D,\"\"(?\"L-A\",P\"[.\"H\".K\"...\"\"!The\"WK\"[WL.\" \"\",\",M\"\";!\"\"[H,\"F\",L,\"D,\"YK:\"II)\"\";@:\"\"(W\"(\"#\"-\"(L!\".\"\". \"\"-P\"-I.\"\"\" ( \"\".-\"(\",\"\"@\"-:\"\",\"(.\"L\"(\"[i\"[\n"
     ]
    }
   ],
   "source": [
    "print(generate('I went on a trip to see Tajmahal in Agra. My trip was'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6cf402-fd87-4690-b7bf-1985d0e507ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_lm.save_pretrained(\"./gpt2_saved_v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25434084-3274-4054-aace-2960dd5a1b28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
